{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajoJINziL91k"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import set_option\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.colors import cnames\n",
    "from itertools import cycle\n",
    "from bokeh.plotting import output_file, figure, show, ColumnDataSource\n",
    "from bokeh.models import HoverTool\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import seaborn as sns; sns.set() \n",
    "rc={'lines.linewidth': 2, 'axes.labelsize': 14, 'axes.titlesize': 14}\n",
    "sns.set(rc=rc)\n",
    "set_option(\"display.max_rows\", 10)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "skNoK-yBIk1c"
   },
   "outputs": [],
   "source": [
    "path_figures = \"./images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path_figures):\n",
    "    os.makedirs(path_figures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wf84QXIBfQ1W"
   },
   "outputs": [],
   "source": [
    "def get_float_list(range_max:int, div:int=100) -> list:\n",
    "    \"\"\" To get 0 -> 1, range_max must be same order of mag as div \"\"\"\n",
    "    return [float(x)/div for x in range(int(range_max))]\n",
    "\n",
    "def get_colorcycle(colordict:dict):\n",
    "    \"\"\" Subset cnames with a string match and get a color cycle for plotting \"\"\"\n",
    "    return cycle(list(colordict.keys()))\n",
    "\n",
    "def get_colordict(filter_:str='dark') -> dict:\n",
    "    \"\"\" return dictionary of colornames by filter \"\"\"\n",
    "    return dict((k, v) for k, v in cnames.items() if filter_ in k)\n",
    "\n",
    "def pca_report_interactive(X, scale_X:bool=True, save_plot:bool=True):\n",
    "    \"\"\"\n",
    "    X:          input data matrix\n",
    "    scale_X:    determine whether to rescale X (StandardScaler) [default: True, X is not prescaled\n",
    "    save_plot:  save plot to file (html) and not show\n",
    "    \"\"\"\n",
    "\n",
    "    # calculate mean and var\n",
    "    X_mean, X_var = X.mean(), X.var()\n",
    "    print('\\n*--- PCA Report ---*\\n')\n",
    "    print(f'X mean:\\t\\t{X_mean:.3f}\\nX variance:\\t{X_var:.3f}')\n",
    "\n",
    "    if scale_X:\n",
    "        # rescale and run PCA\n",
    "        print(\"\\n...Rescaling data...\\n\")\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        X_s_mean, X_s_var = X_scaled.mean(), X_scaled.var()\n",
    "        print(f'X_scaled mean:\\t\\t{np.round(X_s_mean):.3f}')\n",
    "        print(f'X_scaled variance:\\t{np.round(X_s_var):.3f}\\n')\n",
    "        pca_ = PCA().fit(X_scaled)\n",
    "        X_pca = PCA().fit_transform(X)\n",
    "    else:\n",
    "        # run PCA directly\n",
    "        print(\"...Assuming data is properly scaled...\")\n",
    "        pca_ = PCA().fit(X)\n",
    "        X_pca = PCA().fit_transform(X)\n",
    "            \n",
    "    # Get cumulative explained variance for each dimension\n",
    "    pca_evr = pca_.explained_variance_ratio_\n",
    "    cumsum_ = np.cumsum(pca_evr)\n",
    "    \n",
    "    # Get dimensions where var >= 95% and values for variance at 2D, 3D\n",
    "    dim_95 = np.argmax(cumsum_ >= 0.95) + 1\n",
    "    twoD = np.round(cumsum_[1], decimals=3)*100 \n",
    "    threeD = np.round(cumsum_[2], decimals=3)*100\n",
    "    instances_, dims_ =  X.shape\n",
    "    \n",
    "    # check shape of X\n",
    "    if dims_ > instances_:\n",
    "        print(\"WARNING: number of features greater than number of instances.\")\n",
    "        dimensions = list(range(1, instances_+1))\n",
    "    else:\n",
    "        dimensions = list(range(1, dims_+1))\n",
    "    \n",
    "    # Print report\n",
    "    print(\"\\n -- Summary --\")\n",
    "    print(f\"You can reduce from {dims_} to {dim_95} dimensions while retaining 95% of variance.\")\n",
    "    print(f\"2 principal components explain {twoD:.2f}% of variance.\")\n",
    "    print(f\"3 principal components explain {threeD:.2f}% of variance.\")\n",
    "    \n",
    "    \"\"\" - Plotting - \"\"\"\n",
    "    # Create custom HoverTool -- we'll name each ROC curve 'ROC' so we only see info on hover there\n",
    "    hover_ = HoverTool(names=['PCA'], tooltips=[(\"dimensions\", \"@x_dim\"), \n",
    "                                                (\"cumulative variance\", \"@y_cumvar\"),\n",
    "                                                (\"explained variance\", \"@y_var\")])\n",
    "    p_tools = [hover_, 'crosshair', 'zoom_in', 'zoom_out', 'save', 'reset', 'tap', 'box_zoom']\n",
    "\n",
    "    # insert 0 at beginning for cleaner plotting\n",
    "    cumsum_plot = np.insert(cumsum_, 0, 0) \n",
    "    pca_evr_plot = np.insert(pca_evr, 0, 0)\n",
    "    dimensions_plot = np.insert(dimensions, 0, 0)\n",
    "\n",
    "    \"\"\"\n",
    "    ColumnDataSource\n",
    "    - a special type in Bokeh that allows you to store data for plotting\n",
    "    - store data as dict (key:list)\n",
    "    - to plot two keys against one another, make sure they're the same length!\n",
    "    - below:\n",
    "        x_dim    # of dimensions (length = # of dimensions)\n",
    "        y_cumvar # cumulative variance (length = # of dimensions)\n",
    "        var_95   # y = 0.95 (length = # of dimensions)\n",
    "        zero_one # list of 0 to 1\n",
    "        twoD     # x = 2 \n",
    "        threeD   # x = 3 \n",
    "    \"\"\" \n",
    "    \n",
    "    # get sources\n",
    "    source_PCA = ColumnDataSource(data=dict(x_dim = dimensions_plot,y_cumvar = cumsum_plot, y_var = pca_evr_plot))    \n",
    "    source_var95 = ColumnDataSource(data=dict(var95_x = [dim_95]*96, var95_y = get_float_list(96)))\n",
    "    source_twoD = ColumnDataSource(data=dict(twoD_x = [2]*(int(twoD)+1), twoD_y = get_float_list(twoD+1)))\n",
    "    source_threeD = ColumnDataSource(data=dict(threeD_x = [3]*(int(threeD)+1), threeD_y = get_float_list(threeD+1)))\n",
    "\n",
    "    \"\"\" PLOT \"\"\"\n",
    "    # set up figure and add axis labels\n",
    "    p = figure(title='PCA Analysis', tools=p_tools)\n",
    "    p.xaxis.axis_label = f'N of {dims_} Principal Components' \n",
    "    p.yaxis.axis_label = 'Variance Explained (per PC & Cumulative)'\n",
    "    \n",
    "    # add reference lines: y=0.95, x=2, x=3\n",
    "    p.line('twoD_x', 'twoD_y', line_width=0.5, line_dash='dotted', color='#435363', source=source_twoD) # x=2\n",
    "    p.line('threeD_x', 'threeD_y', line_width=0.5, line_dash='dotted', color='#435363', source=source_threeD) # x=3\n",
    "    p.line('var95_x', 'var95_y', line_width=2, line_dash='dotted', color='#435363', source=source_var95) # var = 0.95\n",
    "\n",
    "    # add bar plot for variance per dimension\n",
    "    p.vbar(x='x_dim', top='y_var', width=.5, bottom=0, color='#D9F2EF', source=source_PCA, name='PCA')\n",
    "    \n",
    "    # add cumulative variance (scatter + line)\n",
    "    p.line('x_dim', 'y_cumvar', line_width=1, color='#F79737', source=source_PCA)\n",
    "    p.circle('x_dim', 'y_cumvar', size=7, color='#FF4C00', source=source_PCA, name='PCA')\n",
    "\n",
    "    # change gridlines\n",
    "    p.ygrid.grid_line_alpha = 0.25\n",
    "    p.xgrid.grid_line_alpha = 0.25\n",
    "\n",
    "    # change axis bounds and grid\n",
    "    p.xaxis.bounds = (0, dims_)\n",
    "    p.yaxis.bounds = (0, 1)\n",
    "    p.grid.bounds = (0, dims_)\n",
    "\n",
    "    # save and show p\n",
    "    if save_plot:\n",
    "        output_file(path_figures+'/PCA_analysis.html')\n",
    "    show(p)\n",
    "    \n",
    "    #from bokeh.io import export_svgs\n",
    "    #p.output_backend = \"svg\"\n",
    "    #export_svgs(p, filename=path_figures+'/plot.svg')\n",
    "\n",
    "    # output PCA info as a dataframe\n",
    "    df_PCA = pd.DataFrame({'dimension': dimensions, 'variance_cumulative': cumsum_, 'variance': pca_evr}).set_index(['dimension'])\n",
    "        \n",
    "    return df_PCA, X_pca, pca_evr\n",
    "\n",
    "\n",
    "def pca_feature_correlation(X, X_pca, explained_var, features:list=None, fig_dpi:int=150, save_plot:bool=True):\n",
    "    \"\"\"\n",
    "    1. Get dot product of X and X_pca\n",
    "    2. Run normalizations of X*X_pca\n",
    "    3. Retrieve df/matrices\n",
    "\n",
    "    X:               data (numpy matrix)\n",
    "    X_pca:           PCA\n",
    "    explained_var:   explained variance matrix\n",
    "    features:        list of feature names\n",
    "    fig_dpi:         dpi to use for heatmaps\n",
    "    save_plot:       save plot to file (html) and not show\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add zeroes for data where features > instances\n",
    "    outer_diff = X.T.shape[0] - X_pca.shape[1]\n",
    "    if outer_diff > 0: # outer dims must match to get sq matrix\n",
    "        Z = np.zeros([X_pca.shape[0], outer_diff])\n",
    "        X_pca = np.c_[X_pca, Z]\n",
    "        explained_var = np.append(explained_var, np.zeros(outer_diff))\n",
    "    \n",
    "    # Get correlation between original features (X) and PCs (X_pca)\n",
    "    dot_matrix = np.dot(X.T, X_pca)\n",
    "    print(f\"X*X_pca: {X.T.shape} * {X_pca.shape} = {dot_matrix.shape}\")\n",
    "    \n",
    "    # Correlation matrix -> df\n",
    "    df_dotproduct = pd.DataFrame(dot_matrix)\n",
    "    df_dotproduct.columns = [''.join(['PC', f'{i+1}']) for i in range(dot_matrix.shape[0])]\n",
    "    if any(features): df_dotproduct.index = features    \n",
    "    \n",
    "    # Normalize & Sort\n",
    "    df_n, df_na, df_nabv = normalize_dataframe(df_dotproduct, explained_var, plot_opt=True, save_plot=save_plot)\n",
    "    \n",
    "    return df_dotproduct, df_n, df_na, df_nabv\n",
    "\n",
    "\n",
    "def normalize_dataframe(df, explained_var=None, fig_dpi:int=150, plot_opt:bool=True, save_plot:bool=True):\n",
    "    \"\"\"\n",
    "    1. Get z-normalized df (normalized to µ=0, σ=1)\n",
    "    2. Get absolute value of z-normalized df\n",
    "    3. If explained_variance matrix provided, dot it w/ (2)\n",
    "    \"\"\"\n",
    "    # Normalize, Reindex, & Sort\n",
    "    df_norm = (df.copy()-df.mean())/df.std()\n",
    "    df_norm = df_norm.sort_values(list(df_norm.columns), ascending=False)\n",
    "    \n",
    "    # Absolute value of normalized (& sort)\n",
    "    df_abs = df_norm.copy().abs().set_index(df_norm.index)\n",
    "    df_abs = df_abs.sort_values(by=list(df_abs.columns), ascending=False)\n",
    "    \n",
    "    # Plot\n",
    "    if plot_opt:\n",
    "        # Z-normalized corr matrix\n",
    "        plt.figure(dpi=fig_dpi)\n",
    "        ax_normal = sns.heatmap(df_norm, cmap=\"RdBu\")\n",
    "        ax_normal.set_title(\"Z-Normalized Data\")\n",
    "        if save_plot:\n",
    "            plt.savefig(path_figures+'/Z_normalized_corr_matrix.pdf', format='pdf')\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "        # |Z-normalized corr matrix|  \n",
    "        plt.figure(dpi=fig_dpi)\n",
    "        ax_abs = sns.heatmap(df_abs, cmap=\"Purples\")\n",
    "        ax_abs.set_title(\"|Z-Normalized|\")\n",
    "        if save_plot:\n",
    "            plt.savefig(path_figures+'/Z_normalized_corr_matrix_Abs.pdf', format='pdf')\n",
    "        else:\n",
    "            plt.show()\n",
    "        \n",
    "    # Re-normalize by explained var (& sort)\n",
    "    if explained_var.any():\n",
    "        df_byvar = df_abs.copy()*explained_var\n",
    "        df_byvar = df_byvar.sort_values(by=list(df_norm.columns), ascending=False)\n",
    "        if plot_opt:\n",
    "            plt.figure(dpi=fig_dpi)\n",
    "            ax_relative = sns.heatmap(df_byvar, cmap=\"Purples\")\n",
    "            ax_relative.set_title(\"|Z-Normalized|*Explained_Variance\")\n",
    "            if save_plot:\n",
    "                plt.savefig(path_figures+'/Normalized_corr_matrix.pdf', format='pdf')\n",
    "            else:\n",
    "                plt.show()\n",
    "    else:\n",
    "        df_byvar = None\n",
    "    return df_norm, df_abs, df_byvar\n",
    "\n",
    "\n",
    "def pca_rank_features(df_nabv, verbose:bool=True):\n",
    "    \"\"\"\n",
    "    Given a dataframe df_nabv with dimensions [f, p], where:\n",
    "        f = features (sorted)\n",
    "        p = principal components\n",
    "        df_nabv.values are |Z-normalized X|*pca_.explained_variance_ratio_\n",
    "        \n",
    "    1. Create column of sum of each row, sort by it 'score_'\n",
    "    3. Set index as 'rank'\n",
    "    \"\"\"\n",
    "    df_rank = df_nabv.copy().assign(score_ = df_nabv.sum(axis=1)).sort_values('score_', ascending=False)\n",
    "    df_rank['feature_'] = df_rank.index\n",
    "    df_rank.index = range(1, len(df_rank)+1)\n",
    "    df_rank.drop(df_nabv.columns, axis=1, inplace=True)\n",
    "    df_rank.index.rename('rank', inplace=True)\n",
    "    if verbose: print(df_rank)\n",
    "    return df_rank\n",
    "\n",
    "\n",
    "def pca_full_report(X, features_:list=None, fig_dpi:int=150, save_plot:bool=True):\n",
    "    \"\"\"\n",
    "    Run complete PCA workflow:\n",
    "        1. pca_report_interactive()\n",
    "        2. pca_feature_correlation()\n",
    "        3. pca_rank_features()\n",
    "        \n",
    "    X:            data (numpy array)\n",
    "    features_:    list of feature names\n",
    "    fig_dpi:      image resolution\n",
    "    \n",
    "    \"\"\"\n",
    "    # Retrieve the interactive report\n",
    "    df_pca, X_pca, pca_evr = pca_report_interactive(X, save_plot=save_plot)\n",
    "    # Get feature-PC correlation matrices\n",
    "    df_corr, df_n, df_na, df_nabv = pca_feature_correlation(X, X_pca, pca_evr, features_, fig_dpi, save_plot) \n",
    "    # Get rank for each feature\n",
    "    df_rank = pca_rank_features(df_nabv)\n",
    "    return (df_pca, X_pca, pca_evr, df_corr, df_n, df_na, df_nabv, df_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0BrchNNfRAl"
   },
   "source": [
    "# SHOHAM DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 356,
     "status": "ok",
     "timestamp": 1612818302221,
     "user": {
      "displayName": "Harold Brayan Arteaga Arteaga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifuFvtfytHqsNbMuH0lLSooSCVwDhasTFeUS0Xrg=s64",
      "userId": "02881993551096447470"
     },
     "user_tz": 300
    },
    "id": "TSz5jQiljtJm",
    "outputId": "6156c112-ce2e-45f0-c64b-861e289c44ef"
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "PATH = '../Databases/ShohamDB.csv'\n",
    "Data = pd.read_csv(PATH, names=['Vsl', 'Vsg', 'VisL', 'VisG', 'DenL', 'DenG', 'ST', 'Ang', 'ID', 'Flow Pattern'], header=0)\n",
    "print(Data['Flow Pattern'].value_counts())\n",
    "\n",
    "features = ['Vsl', 'Vsg', 'VisL', 'VisG', 'DenL', 'DenG', 'ST', 'Ang', 'ID']\n",
    "data = np.array(Data[features])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2722,
     "status": "ok",
     "timestamp": 1612818305500,
     "user": {
      "displayName": "Harold Brayan Arteaga Arteaga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifuFvtfytHqsNbMuH0lLSooSCVwDhasTFeUS0Xrg=s64",
      "userId": "02881993551096447470"
     },
     "user_tz": 300
    },
    "id": "SI_J7cbHfUHj",
    "outputId": "7a2cab5e-c626-43bc-9819-146dfbe1d702"
   },
   "outputs": [],
   "source": [
    "MPF_outputs = pca_full_report(X=data, features_= features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gv_z4H7YfixP"
   },
   "source": [
    "# 12 DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1612821235211,
     "user": {
      "displayName": "Harold Brayan Arteaga Arteaga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifuFvtfytHqsNbMuH0lLSooSCVwDhasTFeUS0Xrg=s64",
      "userId": "02881993551096447470"
     },
     "user_tz": 300
    },
    "id": "0Ttr5AjCflkD",
    "outputId": "5432f006-d2db-477f-8fe4-53c8a3e5f726"
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "PATH = '../Databases/12DB_6FP.csv'\n",
    "Data = pd.read_csv(PATH, names=['Vsl', 'Vsg', 'VisL', 'VisG', 'DenL', 'DenG', 'ST', 'Ang', 'ID', 'Flow Pattern'], header=0)\n",
    "print(Data['Flow Pattern'].value_counts())\n",
    "\n",
    "features = ['Vsl', 'Vsg', 'VisL', 'VisG', 'DenL', 'DenG', 'ST', 'Ang', 'ID']\n",
    "data = np.array(Data[features])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2167,
     "status": "ok",
     "timestamp": 1612821237303,
     "user": {
      "displayName": "Harold Brayan Arteaga Arteaga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifuFvtfytHqsNbMuH0lLSooSCVwDhasTFeUS0Xrg=s64",
      "userId": "02881993551096447470"
     },
     "user_tz": 300
    },
    "id": "Q3J3fsgZons0",
    "outputId": "87b31690-cb9e-45f5-e06e-38db75de80cc"
   },
   "outputs": [],
   "source": [
    "MPF_outputs = pca_full_report(X=data, features_= features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uESVBgBVL91v"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Feature_selection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
