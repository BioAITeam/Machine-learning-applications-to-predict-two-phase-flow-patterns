{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fjiQ8aEcAsi"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_rJ6t7_TcCB4"
   },
   "outputs": [],
   "source": [
    "# libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "#Visualizers\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.classifier import ClassPredictionError\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from yellowbrick.classifier import PrecisionRecallCurve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "#Classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Neural Network\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import tensorflow as tf\n",
    "\n",
    "import time as tm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 464,
     "status": "ok",
     "timestamp": 1617394211403,
     "user": {
      "displayName": "Harold Brayan Arteaga Arteaga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjjrrXNz7QPLJHtdLrEc1wTzeZ3UoCoBWASA8kIw=s64",
      "userId": "02881993551096447470"
     },
     "user_tz": 300
    },
    "id": "iBhb1c9hgBq2"
   },
   "outputs": [],
   "source": [
    "def FullyConnected():\n",
    "  inputs = Input(shape=(X_train.shape[1],), name=\"input_1\")\n",
    "  layers = Dense(512, activation=\"selu\")(inputs)\n",
    "  layers = Dense(256, activation=\"selu\")(layers)\n",
    "  layers = Dense(128, activation=\"selu\")(layers)\n",
    "  layers = Dense(64, activation=\"selu\")(layers)\n",
    "  predictions = Dense(len(classes), activation=\"softmax\", name=\"output_1\")(layers)\n",
    "  model = Model(inputs = inputs, outputs=predictions)\n",
    "  optimizer=RMSprop() \n",
    "  model.compile(optimizer=optimizer,\n",
    "                loss='categorical_crossentropy',  \n",
    "                metrics=['accuracy'])\n",
    "  return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJvQprZicYNG"
   },
   "source": [
    "# 6 CLASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1466,
     "status": "ok",
     "timestamp": 1617394162939,
     "user": {
      "displayName": "Harold Brayan Arteaga Arteaga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjjrrXNz7QPLJHtdLrEc1wTzeZ3UoCoBWASA8kIw=s64",
      "userId": "02881993551096447470"
     },
     "user_tz": 300
    },
    "id": "v8PSoxkEcXpP",
    "outputId": "92413315-3de4-4ff4-f43b-ba9c297164f7"
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "PATH = './DataBase/New_BD12Exp6FP.csv'\n",
    "Data = pd.read_csv(PATH, names=['Vsl', 'Vsg', 'VisL', 'VisG', 'DenL', 'DenG', 'ST', 'Ang', 'ID', 'Flow Pattern'], header=0)\n",
    "print('Data shape:', Data.shape)\n",
    "# Train, test split\n",
    "features_list = ['Vsl', 'Vsg', 'VisL', 'VisG', 'DenL', 'DenG', 'ST', 'Ang', 'ID']\n",
    "Features = Data[features_list]\n",
    "Labels = Data['Flow Pattern']\n",
    "X_train, X_test, y_train, y_test = train_test_split(Features, Labels, test_size=0.2, stratify=Labels, random_state=42)\n",
    "print('Train data shape:', X_train.shape)\n",
    "print('Train labels shape:', y_train.shape)\n",
    "print('Test data shape:', X_test.shape)\n",
    "print('Test labels shape:', y_test.shape)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qxx8jQpDcTZD"
   },
   "outputs": [],
   "source": [
    "classes = [0, 1, 2, 3, 4, 5] \n",
    "model = FullyConnected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 147102,
     "status": "ok",
     "timestamp": 1602223361066,
     "user": {
      "displayName": "Harold Brayan Arteaga Arteaga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifuFvtfytHqsNbMuH0lLSooSCVwDhasTFeUS0Xrg=s64",
      "userId": "02881993551096447470"
     },
     "user_tz": 300
    },
    "id": "_nks6LOhcERj",
    "outputId": "5439bf64-a2b5-4002-b256-4ed6c85652ae"
   },
   "outputs": [],
   "source": [
    "y_train_ = to_categorical(y_train, num_classes=len(classes)) \n",
    "y_test_ = to_categorical(y_test, num_classes=len(classes)) \n",
    "lossTRAIN,accuracyTRAIN = model.evaluate(X_train, y_train_,verbose=None)\n",
    "lossTEST,accuracyTEST   = model.evaluate(X_test, y_test_,verbose=None)\n",
    "start_time = tm.time()\n",
    "history=model.fit(X_train, y_train_, epochs=400, batch_size=64,validation_data=(X_test, y_test_),verbose=None)\n",
    "TIME = tm.time() - start_time\n",
    "print(\"Time \"+str(len(classes))+\" classes = %s [seconds]\" % int(TIME))\n",
    "\n",
    "with plt.style.context('seaborn-white'):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    #Plot training & validation accuracy values\n",
    "    plt.plot(np.concatenate([np.array([accuracyTRAIN]),np.array(history.history['accuracy'])],axis=0))\n",
    "    plt.plot(np.concatenate([np.array([accuracyTEST]), np.array(history.history['val_accuracy'])],axis=0))\n",
    "    plt.title('Accuracy Vs Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.grid('on')\n",
    "    plt.savefig(\"./6FP/\"+str(len(classes))+\"_NN_ACC.pdf\", format='pdf')\n",
    "    plt.show()\n",
    "        \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    #Plot training & validation loss values\n",
    "    plt.plot(np.concatenate([np.array([lossTRAIN]),np.array(history.history['loss'])],axis=0))\n",
    "    plt.plot(np.concatenate([np.array([lossTEST]), np.array(history.history['val_loss'])],axis=0))\n",
    "    plt.title('Loss Vs Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.grid('on')\n",
    "    plt.savefig(\"./6FP/\"+str(len(classes))+\"_NN_LOSS.pdf\", format='pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knVbFIwFccCG"
   },
   "source": [
    "# 5 CLASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "executionInfo": {
     "elapsed": 144852,
     "status": "ok",
     "timestamp": 1602222915926,
     "user": {
      "displayName": "Harold Brayan Arteaga Arteaga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifuFvtfytHqsNbMuH0lLSooSCVwDhasTFeUS0Xrg=s64",
      "userId": "02881993551096447470"
     },
     "user_tz": 300
    },
    "id": "buKIOpPJcc8z",
    "outputId": "d5e8f80a-6712-42b0-bce2-676999d0472b"
   },
   "outputs": [],
   "source": [
    "# Load Dataset \n",
    "PATH = './DataBase/New_BD12Exp5FP.csv'\n",
    "Data = pd.read_csv(PATH, names=['Vsl', 'Vsg', 'VisL', 'VisG', 'DenL', 'DenG', 'ST', 'Ang', 'ID', 'Flow Pattern'], header=0)\n",
    "print('Data shape:', Data.shape)\n",
    "# Train, test split\n",
    "features_list = ['Vsl', 'Vsg', 'VisL', 'VisG', 'DenL', 'DenG', 'ST', 'Ang', 'ID']\n",
    "Features = Data[features_list]\n",
    "Labels = Data['Flow Pattern']\n",
    "X_train, X_test, y_train, y_test = train_test_split(Features, Labels, test_size=0.2, stratify=Labels, random_state=42)\n",
    "print('Train data shape:', X_train.shape)\n",
    "print('Train labels shape:', y_train.shape)\n",
    "print('Test data shape:', X_test.shape)\n",
    "print('Test labels shape:', y_test.shape)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgQxGPH7cdSb"
   },
   "outputs": [],
   "source": [
    "classes = [0, 1, 2, 3, 4]\n",
    "model = FullyConnected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 291833,
     "status": "ok",
     "timestamp": 1602223062932,
     "user": {
      "displayName": "Harold Brayan Arteaga Arteaga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifuFvtfytHqsNbMuH0lLSooSCVwDhasTFeUS0Xrg=s64",
      "userId": "02881993551096447470"
     },
     "user_tz": 300
    },
    "id": "FAhpv5fPcdVx",
    "outputId": "9259713a-8356-4360-d9a7-40ab8e41bd56"
   },
   "outputs": [],
   "source": [
    "y_train_ = to_categorical(y_train, num_classes=len(classes)) \n",
    "y_test_ = to_categorical(y_test, num_classes=len(classes)) \n",
    "lossTRAIN,accuracyTRAIN = model.evaluate(X_train, y_train_,verbose=None)\n",
    "lossTEST,accuracyTEST   = model.evaluate(X_test, y_test_,verbose=None)\n",
    "start_time = tm.time()\n",
    "history=model.fit(X_train, y_train_, epochs=400, batch_size=64,validation_data=(X_test, y_test_),verbose=None)\n",
    "TIME = tm.time() - start_time\n",
    "print(\"Time \"+str(len(classes))+\" classes = %s [seconds]\" % int(TIME))\n",
    "with plt.style.context('seaborn-white'):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    #Plot training & validation accuracy values\n",
    "    plt.plot(np.concatenate([np.array([accuracyTRAIN]),np.array(history.history['accuracy'])],axis=0))\n",
    "    plt.plot(np.concatenate([np.array([accuracyTEST]), np.array(history.history['val_accuracy'])],axis=0))\n",
    "    plt.title('Accuracy Vs Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.grid('on')\n",
    "    plt.savefig(\"./5FP/\"+str(len(classes))+\"_NN_ACC.pdf\", format='pdf')\n",
    "    plt.show()\n",
    "        \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    #Plot training & validation loss values\n",
    "    plt.plot(np.concatenate([np.array([lossTRAIN]),np.array(history.history['loss'])],axis=0))\n",
    "    plt.plot(np.concatenate([np.array([lossTEST]), np.array(history.history['val_loss'])],axis=0))\n",
    "    plt.title('Loss Vs Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.grid('on')\n",
    "    plt.savefig(\"./5FP/\"+str(len(classes))+\"_NN_LOSS.pdf\", format='pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDu2BbO5cdcD"
   },
   "source": [
    "# 3 CLASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "executionInfo": {
     "elapsed": 559,
     "status": "ok",
     "timestamp": 1602223066935,
     "user": {
      "displayName": "Harold Brayan Arteaga Arteaga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifuFvtfytHqsNbMuH0lLSooSCVwDhasTFeUS0Xrg=s64",
      "userId": "02881993551096447470"
     },
     "user_tz": 300
    },
    "id": "CzbvOD4mcfYE",
    "outputId": "3ea0e265-1959-46f7-fe41-86a2b9cf0307"
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "PATH = './DataBase/New_BD12Exp3FP.csv'\n",
    "Data = pd.read_csv(PATH, names=['Vsl', 'Vsg', 'VisL', 'VisG', 'DenL', 'DenG', 'ST', 'Ang', 'ID', 'Flow Pattern'], header=0)\n",
    "print('Data shape:', Data.shape)\n",
    "# Train, test split\n",
    "features_list = ['Vsl', 'Vsg', 'VisL', 'VisG', 'DenL', 'DenG', 'ST', 'Ang', 'ID']\n",
    "Features = Data[features_list]\n",
    "Labels = Data['Flow Pattern']\n",
    "X_train, X_test, y_train, y_test = train_test_split(Features, Labels, test_size=0.2, stratify=Labels, random_state=42)\n",
    "print('Train data shape:', X_train.shape)\n",
    "print('Train labels shape:', y_train.shape)\n",
    "print('Test data shape:', X_test.shape)\n",
    "print('Test labels shape:', y_test.shape)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3nc23nQhcgSQ"
   },
   "outputs": [],
   "source": [
    "classes = [0, 1, 2] \n",
    "model = FullyConnected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 147079,
     "status": "ok",
     "timestamp": 1602223213496,
     "user": {
      "displayName": "Harold Brayan Arteaga Arteaga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifuFvtfytHqsNbMuH0lLSooSCVwDhasTFeUS0Xrg=s64",
      "userId": "02881993551096447470"
     },
     "user_tz": 300
    },
    "id": "O6qbnM6acgUy",
    "outputId": "e88a4570-b200-4306-d295-437f48243499"
   },
   "outputs": [],
   "source": [
    "y_train_ = to_categorical(y_train, num_classes=len(classes)) \n",
    "y_test_ = to_categorical(y_test, num_classes=len(classes)) \n",
    "lossTRAIN,accuracyTRAIN = model.evaluate(X_train, y_train_,verbose=None)\n",
    "lossTEST,accuracyTEST   = model.evaluate(X_test, y_test_,verbose=None)\n",
    "start_time = tm.time() \n",
    "history=model.fit(X_train, y_train_, epochs=400, batch_size=64,validation_data=(X_test, y_test_),verbose=None)\n",
    "TIME = tm.time() - start_time\n",
    "print(\"Time \"+str(len(classes))+\" classes = %s [seconds]\" % int(TIME))\n",
    "with plt.style.context('seaborn-white'):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    #Plot training & validation accuracy values\n",
    "    plt.plot(np.concatenate([np.array([accuracyTRAIN]),np.array(history.history['accuracy'])],axis=0))\n",
    "    plt.plot(np.concatenate([np.array([accuracyTEST]), np.array(history.history['val_accuracy'])],axis=0))\n",
    "    plt.title('Accuracy Vs Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.grid('on')\n",
    "    plt.savefig(\"./3FP/\"+str(len(classes))+\"_NN_ACC.pdf\", format='pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    #Plot training & validation loss values\n",
    "    plt.plot(np.concatenate([np.array([lossTRAIN]),np.array(history.history['loss'])],axis=0))\n",
    "    plt.plot(np.concatenate([np.array([lossTEST]), np.array(history.history['val_loss'])],axis=0))\n",
    "    plt.title('Loss Vs Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.grid('on')\n",
    "    plt.savefig(\"./3FP/\"+str(len(classes))+\"_NN_LOSS.pdf\", format='pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_Ek9lDJcggs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOnTfLULIS/Qhv6h3XvlZKS",
   "collapsed_sections": [
    "knVbFIwFccCG"
   ],
   "mount_file_id": "1SG7peGhl6G_p12xxZuBU3bSh7wcCMEBg",
   "name": "NN Graphics Acc and Loss.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "MPF",
   "language": "python",
   "name": "mpf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
